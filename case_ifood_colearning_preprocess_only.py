# -*- coding: utf-8 -*-
"""Case_Ifood_Colearning_Preprocess_Only.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CvqOftaMws0TsGqZQwEhNdQHMblhx2bt

# Case Ifood
*Desenvolvido por Mário de Deus*

*Adaptado por Nickolas, Marcos e Sandron para o CP1*

# Installs
"""

# # Instalar o numba primeiro, na versão compatível
# !pip install numba

# # Instalar o shap (caso queira garantir uma versão mais recente)
# !pip install shap

# !pip install pycaret

# !pip install pandas==1.5.3
import importlib
#importlib.reload(pandas)  # Atualiza pandas no runtime, só por garantia

# import sklearn
# sklearn.__version__

"""# Imports"""

import numpy as np
import pandas as pd
import joblib
from pycaret.classification import setup, load_model, evaluate_model
# import seaborn as sns
# import shap

from pycaret.classification import *

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 40)
pd.set_option('display.max_colwidth', 1000)

import warnings
warnings.filterwarnings('ignore')

"""# Descrição / Objetivo do problema

* O objetivo

O objetivo da equipe é construir um modelo preditivo que produzirá o maior lucro para a próxima campanha de marketing direto, programada para o próximo mês. A nova campanha, sexta, visa a venda de um novo gadget para clientes cadastrados no Banco de Dados da empresa. Para construir o modelo, foi realizada uma campanha piloto envolvendo 2.240 clientes. Os clientes foram selecionados aleatoriamente e contatados por telefone para a aquisição do gadget. Durante os meses seguintes, os clientes que compraram a oferta foram devidamente etiquetados. O custo total da campanha da amostra foi de 6,720MU e a receita gerada pelos clientes que aceitaram a oferta foi de 3,674MU. Globalmente, a campanha teve um lucro de -3,046MU. A taxa de sucesso da campanha foi de 15%. O objetivo da equipe é desenvolver um modelo que preveja o comportamento do cliente e aplicá-lo ao restante da base de clientes. Felizmente, o modelo permitirá que a empresa escolha a dedo os clientes com maior probabilidade de comprar a oferta, deixando de fora os não respondentes, tornando a próxima campanha altamente lucrativa. Além disso, além de maximizar o lucro da campanha, o CMO está interessado em estudar as características dos clientes que desejam comprar o gadget.
Os dados
O conjunto de dados contém características sociodemográficas e firográficas de cerca de 2.240 clientes contatados. Além disso, contém um sinalizador para aqueles clientes que responderam à campanha, comprando o produto.

# Data Loading
"""

# from google.colab import drive
# drive.mount('/content/drive')

#Google COlab
# df = pd.read_csv('/content/drive/MyDrive/Front End e Mobile Development/2024/20240318 - Aula06/data.csv',encoding='utf-8')

#Jupyter
df = pd.read_csv('data.csv',encoding='utf-8')

df.head()

"""# Data Cleaning

Drop da feature ID por ser um identificador
"""

df.drop('ID',axis = 1, inplace = True, errors = 'ignore')
df.shape

"""## Features com valores unicos
Verificando a existência de features com valores únicos (devem ser dropadas por não contribuirem para a explicar a variação da feature target)
"""

df.nunique().sort_values()

df.drop(['Z_CostContact','Z_Revenue'],axis=1,inplace = True, errors = 'ignore')

"""## NaN analysis"""

df.isna().sum()

"""Somente a feature Income possui valores nulos.
Analisando as linhas com valores nulos em relação aos valores da feature target
"""

#Distribuição da feature Response entre as amostras com Income = NaN
df[df.Income.isna()].Response.value_counts()

# Proporção de 0 e 1 da feature Response no df completo
df.Response.value_counts(normalize = True)

print('% amostras com NaN: ',np.round((df.Income.isna().sum()/len(df))*100,2))
print('% amostras com NaN e Response = 1: ',
      np.round((( len(df[(df.Income.isna()) & (df.Response == 1)]) / len(df))*100),2))

"""Dado que as 24 linhas com valores Nan representam 1% do dataset total, e que entre as 24 linhas com Income == Nan somente uma apresentou Response == 1 (0.04%), as 24 linhas serão dropadas"""

print('Shape antes do dropna: ',df.shape[0])
df.dropna(axis=0,inplace = True)
print('Shape após o dropna: ',df.shape[0])

"""## Ajuste do dtypes"""

df = df.convert_dtypes()
df.Dt_Customer = pd.to_datetime(df.Dt_Customer)
df.Response = df.Response.astype('bool')
df.dtypes

"""# Feature Engineering

## Idade dos clientes
"""

from datetime import datetime
ano_atual = pd.datetime.now().year
df['Age'] = ano_atual - df.Year_Birth
df.drop('Year_Birth',axis = 1, errors = 'ignore', inplace = True)
df.head()

"""## Tempo como cliente"""

dt = pd.datetime.now().date()
df['Time_Customer'] = dt - pd.to_datetime(df['Dt_Customer']).dt.date
df['Time_Customer'] = df['Time_Customer'] / np.timedelta64(1, 'Y')
print(df[['Dt_Customer','Time_Customer']].head())
df.drop('Dt_Customer',axis = 1, inplace = True)

"""### Removendo valores incoerentes com a variável Marital_Status"""

index_to_drop = df[(df['Marital_Status'] =='YOLO') | (df['Marital_Status'] =='Absurd') | (df['Marital_Status'] =='absurd') | (df['Marital_Status'] == 'Alone')].index
df.drop(index_to_drop,inplace = True)
df = df.reset_index(drop = True)
df.Marital_Status.value_counts()
print(df.shape)

df.rename(columns={'Response':'z_Response'},inplace = True)
cols = df.columns.sort_values()
df = df[cols]
df.rename(columns={'z_Response':'Response'},inplace = True)

df.columns

"""# Preparação do dataset para Modelagem

## Train Test Validation Split
"""

# sample 5% of data to be used as unseen data
df_train_test = df.sample(frac=0.90, random_state=123)
df_valid = df.drop(df_train_test.index)
df_train_test.reset_index(inplace=True, drop=True)
df_valid.reset_index(inplace=True, drop=True)
# print the revised shape
print('Data for Modeling: ' + str(df_train_test.shape))
print('Unseen Data For Predictions: ' + str(df_valid.shape))

"""# Auto ML - PYCARET

**Para o problema de negócio em questão, a métrica Precision é a mais relevante.**
"""

df_train_test.dtypes

"""## Setup"""

s = setup(data = df_train_test,
          target = 'Response',
          fix_imbalance = True,
          remove_outliers = True,
          categorical_features = ['Education', 'Marital_Status'],
          session_id = 123)

# check available models
#has to be called necessary only after having defined a setup.
models()

"""## Comparativo entre Modelos"""

best_model = compare_models(sort = 'auc')

# print(best_model)

"""## Análise do Modelo"""

#evaluate model
# evaluate_model(best_model)

#plot model - treshold
# plot_model(best_model, plot = 'threshold')

#plot model - auc
# plot_model(best_model, plot = 'auc')

#plot model - confusion matrix
#plot_model(best_model, plot = 'confusion_matrix')

#plot model - feature
#plot_model(best_model, plot = 'feature')

#predict model - raw score
#predict_model(best_model, raw_score= True)

"""* Outros tipos de plot:
https://pycaret.readthedocs.io/en/latest/api/classification.html#pycaret.classification.plot_model

## Criando um Modelo
"""

#create model rf
mdl_gbc = create_model('gbc')

"""## Tuning dos Hiperparâmetros

### RF
"""

tuned_gbc = tune_model(mdl_gbc)

#predict rf
#mdl_rf com e sem tuning apresentaram AUC e desvio padrao (STD) praticamente iguais.
predict_model(mdl_gbc, raw_score = True)

print(mdl_gbc)

print(tuned_gbc)

#predict rf
predict_model(tuned_gbc, raw_score = True)

"""## AUC Plot"""

#auc
#plot_model(tuned_rf, plot = 'auc')

"""## Feature Importance"""

#feature
#plot_model(tuned_rf, plot = 'feature')

"""## Matriz de Confusão"""

#confusion matrix
#plot_model(tuned_rf, plot = 'confusion_matrix')

"""## Save Model"""

save_model(mdl_gbc, './deploy/pickle/pickle_gbc_pycaret2')

cols_x_test = get_config(variable="X_test").columns
cols_x_test

df_valid.drop('Response', axis = 1).to_csv('Xtest.csv', index = False)

df_valid